{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d33589",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import torch\n",
    "\n",
    "# Define constants\n",
    "num_samples = 2500  # Number of images\n",
    "image_shape = (32, 32, 3)  # Original image shape\n",
    "num_classes = 10  # Number of classes\n",
    "epochs = 5  # Number of epochs\n",
    "data = torch.load('../dataset/dataset/part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "\n",
    "# Generate synthetic image data for demonstration (random RGB images)\n",
    "images = data['data']\n",
    "\n",
    "# Generate synthetic target labels (random integers in range of num_classes)\n",
    "targets = data['targets']\n",
    "# Convert integer labels to one-hot encoded vectors\n",
    "one_hot_labels = tf.keras.utils.to_categorical(targets, num_classes=num_classes)\n",
    "\n",
    "# Resize images to the required input size for ResNet50V2 (224, 224, 3)\n",
    "resized_images = tf.image.resize(images, (224, 224))\n",
    "\n",
    "# Preprocess images using ResNet50V2 preprocessing\n",
    "processed_images = preprocess_input(resized_images)\n",
    "\n",
    "# Load ResNet50V2 as the base model with pre-trained ImageNet weights\n",
    "base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model to use it as a feature extractor\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)  # Pass input through the base model\n",
    "x = GlobalAveragePooling2D()(x)  # Pool the output feature maps into a single feature vector\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)  # Output layer for classification\n",
    "\n",
    "# Define the complete model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Define callbacks to manage training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"loss\", factor=0.1, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train the model for feature extraction\n",
    "print(\"\\nTraining the model:\")\n",
    "model.fit(\n",
    "    processed_images,\n",
    "    one_hot_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create a feature extractor from the trained ResNet50V2 base model\n",
    "print(\"\\nExtracting features using the base model:\")\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Use the feature extractor to extract features from the images\n",
    "features = feature_extractor.predict(processed_images, batch_size=32)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(f\"Extracted features shape: {features.shape}\")  # Example: (2500, 7, 7, 2048)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
