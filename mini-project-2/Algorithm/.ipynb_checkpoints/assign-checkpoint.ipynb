{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932b7e50-1dfd-41cf-8262-3c6481881b07",
   "metadata": {},
   "source": [
    "## ignoring warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07d70df-6c69-4f9f-99f6-187a900aab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e1431-5625-4e33-b9cf-8fc1a6ea1f4c",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9c220d-fa56-4b60-a2bb-f3a4c3f4c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.load('../dataset/dataset/part_one_dataset/train_data/1_train_data.tar.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d063a-f6b2-49d6-a576-f0ee4e60197b",
   "metadata": {},
   "source": [
    "## Analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb30952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39512559-c29e-4b37-b5e3-ff3605f71cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'targets'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34fa842-ec9f-49b1-971d-904e79fee36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 32, 32, 3)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "print(data['data'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b97c97-c355-4b1a-97f0-c427959faa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3634371-e639-4c7a-a4c4-f0761ae36de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275f45e-eec4-457c-bcea-ad7f5094b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['data'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb2040-71ab-42bd-a35e-eae62c1d0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284106d8-8076-46a9-a127-e399ca9c9e9f",
   "metadata": {},
   "source": [
    "## Converting dict to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047b0a2-4aa2-4a8e-b600-ba7e54f741f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['targets']))\n",
    "print(type(data['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163e980-9a6e-4330-9394-d48d9c572333",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['targets'].shape)\n",
    "print(data['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f1c26-9d37-4bc7-9b83-7c23efea4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['targets'])\n",
    "df.columns = ['targets']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f38be8-c2da-41f9-b020-7fb812942b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f025950-82d2-4b38-97eb-978f7cbf4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='targets', data=df)\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Frequency of Values in Column1')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf53e6-8b8e-4fda-be3d-3c068c59a153",
   "metadata": {},
   "source": [
    "## Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a26b4d-1b9e-4c06-bf3b-39dcde1cc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "X_train = data['data']  # 2500 images, 32x32x3 shape\n",
    "y_train = data['targets']   # 10 classes (0-9)\n",
    "\n",
    "# Create a CNN model for feature extraction\n",
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "# Convolutional Layer 1\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Convolutional Layer 2\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Flatten the output of the last convolutional layer\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Fully connected layers (optional for classification)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Build the model\n",
    "cnn_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Perform a dummy pass to initialize the model and its weights\n",
    "cnn_model.predict(np.random.rand(1, 32, 32, 3))  # A dummy pass to initialize the model\n",
    "\n",
    "# Now, remove the classification layers and only output the features\n",
    "# Access the last convolutional layer (before flattening) for feature extraction\n",
    "feature_extractor = Model(inputs=cnn_model.input, outputs=cnn_model.layers[2].output)  # The second conv layer is at index 2\n",
    "\n",
    "# Extract features from the CNN model (this will be a 2D array of shape (2500, num_features))\n",
    "features = feature_extractor.predict(X_train)\n",
    "\n",
    "print(f\"Extracted Features Shape: {features.shape}\")  # Should print the shape like (2500, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b829c98-1985-4a2d-bc25-f47f484e91ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2e909-c43b-4b21-a1cc-1d557ea97d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac5dea-c65d-414d-b5ea-5a7745642a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52ccf9-c63c-4b5d-abfe-86dbed815d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Now, 'features_flat' contains the extracted features\n",
    "print(features_flat.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffaa002-f80b-4d5e-867a-e3d03ade6026",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bbcb0-d58c-4fa1-b2ee-bd90cda9e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assume features_flat is your flattened feature array from the pretrained model\n",
    "# For example, features_flat.shape = (2500, 25088) for VGG16\n",
    "\n",
    "# Initialize PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "features_reduced = pca.fit_transform(features_flat)\n",
    "\n",
    "print(features_reduced.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99abe3ce-2411-4a2b-9ea4-747a3e543c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(features_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc79f07-e636-4124-b597-8196584948b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_reduced[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bef4ed-13e4-44d7-9630-2f25bed36f81",
   "metadata": {},
   "source": [
    "## Converting to Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb619c-86dd-454a-8859-d793e9a7614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the reduced feature set (features_reduced)\n",
    "features_standardized = scaler.fit_transform(features_reduced)\n",
    "\n",
    "# Now, 'features_standardized' is standardized and ready for use\n",
    "\n",
    "print(features_standardized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ba307-6cd0-4434-bf5c-f35eefaf7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(features_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d8b74-6880-495b-8664-b8bb4012b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f180cf6-310c-4f53-9396-314c9648fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_data,df],axis = 1)\n",
    "print(df_concat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48358dff-ae8e-4ed2-835e-403d6cbb06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((features_standardized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65920f46-9e22-438b-a202-9d59caf0885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['targets']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f28de-edf1-477a-8545-d38b512fa665",
   "metadata": {},
   "source": [
    "## DO the lwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1c901-773c-4194-ad7a-9b556dda8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = data['targets']\n",
    "X = features_standardized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12788b7-5363-44a5-81d3-687a19ebd2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example: X is your input data (already transformed, standardized, and linearized)\n",
    "# y is your labels (integers from 0 to 9 for 10 classes)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data to fit LSTM input requirements (LSTM expects 3D input)\n",
    "# Here, we reshape X_train and X_test from shape (num_samples, num_features) to (num_samples, timesteps, features)\n",
    "# We can consider each feature as a timestep, with 1 feature per timestep (timesteps=1).\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))  # (num_samples, timesteps=1, num_features)\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))      # (num_samples, timesteps=1, num_features)\n",
    "\n",
    "# Build the neural network model with an LSTM layer\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (since X has already been transformed, we start with the feature size directly)\n",
    "model.add(LSTM(128, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), activation='relu', return_sequences=False))  # LSTM layer\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(128, activation='relu'))  # Second hidden layer\n",
    "model.add(Dense(64, activation='softmax'))  # Output layer with 10 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Get the predicted class (the class with the highest probability)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91321ed-2dbe-4e9e-a84a-2b20396d2beb",
   "metadata": {},
   "source": [
    "### Analyzing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954061a-93b4-4607-980d-c3dc5163fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89984fa9-8278-4d05-8f79-0d7c36377bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2500):\n",
    "    img = Image.fromarray(data['data'][i])\n",
    "    target_dir = f\"./{data['targets'][i]}\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    img.save(f\"{target_dir}/img{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72dd15-ad93-4c59-ba23-553b54d6e14d",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e9ae71f-4108-4f59-b296-324de12f9a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │              \u001b[38;5;34m52\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188</span> (752.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m188\u001b[0m (752.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188</span> (752.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m188\u001b[0m (752.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Extracted features shape: (2500, 512)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "images = data['data']\n",
    "# Enhanced CNN Model for feature extraction\n",
    "model = tf.keras.Sequential([\n",
    "    # First Convolutional Block\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=4,  # Number of filters for learning low-level features\n",
    "        kernel_size=(2, 2),  # Filter size\n",
    "        strides=(1, 1),  # No down-sampling yet\n",
    "        padding='same',  # Keeps output size same\n",
    "        activation='relu',  # ReLU activation\n",
    "        input_shape=(32, 32, 3)  # Input shape for RGB images\n",
    "    ),\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),  # Reduce height and width by 2\n",
    "        strides=(2, 2),\n",
    "        padding='valid'  # Reduce size\n",
    "    ),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=8,  # Double the filters for learning mid-level features\n",
    "        kernel_size=(2, 2),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=(2, 2),\n",
    "        padding='valid'\n",
    "    ),\n",
    "\n",
    "    # # Third Convolutional Block\n",
    "    # tf.keras.layers.Conv2D(\n",
    "    #     filters=8,  # Increase filters for high-level features\n",
    "    #     kernel_size=(3, 3),\n",
    "    #     strides=(2, 2),\n",
    "    #     padding='same',\n",
    "    #     activation='relu'\n",
    "    # ),\n",
    "    # tf.keras.layers.MaxPooling2D(\n",
    "    #     pool_size=(2, 2),\n",
    "    #     strides=(2, 2),\n",
    "    #     padding='valid'\n",
    "    # ),\n",
    "\n",
    "    # # Fourth Convolutional Block\n",
    "    # tf.keras.layers.Conv2D(\n",
    "    #     filters=16,  # Increase further for richer high-level features\n",
    "    #     kernel_size=(3, 3),\n",
    "    #     strides=(2, 2),\n",
    "    #     padding='same',\n",
    "    #     activation='relu'\n",
    "    # ),\n",
    "    # tf.keras.layers.MaxPooling2D(\n",
    "    #     pool_size=(2, 2),\n",
    "    #     strides=(2, 2),\n",
    "    #     padding='valid'\n",
    "    # ),\n",
    "\n",
    "    # Flatten the features to use later or pass through Dense layers\n",
    "    tf.keras.layers.Flatten()\n",
    "])\n",
    "\n",
    "# Summary of the enhanced model\n",
    "model.summary()\n",
    "\n",
    "# Extract features using the enhanced model\n",
    "features = model.predict(images)\n",
    "\n",
    "# Print feature shape\n",
    "print(f\"Extracted features shape: {features.shape}\")  # Example: (10, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58611761-22a5-435e-b627-5c7f35e81c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 224)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assume features_flat is your flattened feature array from the pretrained model\n",
    "# For example, features_flat.shape = (2500, 25088) for VGG16\n",
    "\n",
    "# Initialize PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "features_reduced = pca.fit_transform(features)\n",
    "\n",
    "print(features_reduced.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781af6c8-e20d-484c-9c94-a6e8772f8c32",
   "metadata": {},
   "source": [
    "### Tsne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39a66d60-327d-42aa-ace8-fb4aaac4d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5387ef27-c22c-468f-882e-faccaaf2bb1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m features_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a scatter plot where each class will have a different color\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=y, cmap='jet', s=50, alpha=0.7)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# # Show the plot\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1136\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \n\u001b[0;32m   1117\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1136\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:900\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSNE with method=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m does not accept sparse \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed distance matrix. Use method=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    896\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor provide the dense distance matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    897\u001b[0m         )\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 900\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    901\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_components\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be inferior to 4 for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    902\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut algorithm as it relies on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    903\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquad-tree or oct-tree.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m     )\n\u001b[0;32m    905\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    907\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree."
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=4, random_state=42)\n",
    "features_2d = tsne.fit_transform(features)\n",
    "\n",
    "# Create a scatter plot where each class will have a different color\n",
    "# scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=y, cmap='jet', s=50, alpha=0.7)\n",
    "\n",
    "# # Add a color bar\n",
    "# plt.colorbar(scatter, label='Class')\n",
    "\n",
    "# # Set plot labels and title\n",
    "# plt.xlabel('t-SNE Component 1')\n",
    "# plt.ylabel('t-SNE Component 2')\n",
    "# plt.title('t-SNE visualization of high-dimensional data')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86214c0b-009e-4032-85e3-a7e10403ee4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m umap_model \u001b[38;5;241m=\u001b[39m \u001b[43mumap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUMAP\u001b[49m(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m features_2d \u001b[38;5;241m=\u001b[39m umap_model\u001b[38;5;241m.\u001b[39mfit_transform(features)  \u001b[38;5;66;03m# Apply UMAP\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "umap_model = umap.UMAP(n_components=20, random_state=42)\n",
    "features_2d = umap_model.fit_transform(features)  # Apply UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83704096-cb84-4b9e-84c4-c994ce8ccd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c1d6507-8a70-4c93-8932-b1282ef341a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_2d\n",
    "y = data['targets']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c10365d-06e5-4504-975b-21e0d92e179c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6d060-e847-4edd-8e99-1cab1327ebf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af311477-f53e-48db-b1f6-868ddb30adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 512)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize the input data (optional but recommended)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53fa8232-e296-4c96-858f-5299086d7640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 69.677765     0.           0.         165.73352      0.\n",
      " 176.1767      31.34619    127.75385     83.99743      0.\n",
      "   0.         229.00185      0.         169.65599     14.078581\n",
      " 155.83363     88.53352      0.           0.         244.74388\n",
      "   0.         202.96416     40.917416   146.73787     69.33796\n",
      "   0.           0.         224.71765      0.         201.28569\n",
      "  67.99785    163.4591      62.88956      0.           0.\n",
      " 229.5444       0.         183.10992     27.285147   161.21759\n",
      "  44.857487     2.6172452    0.         120.701004     0.\n",
      "  79.66397      3.984033    93.256294    27.527452     0.\n",
      "   0.          81.49945      0.          72.94427     17.175558\n",
      "  57.538002    14.803525     0.           0.          84.30511\n",
      "   0.          54.622143     7.3381886   53.97275     93.98909\n",
      "   0.           0.         193.22508      0.         126.08862\n",
      "  41.226246    97.7383      38.62818      0.           0.\n",
      " 201.33678      0.          96.200615     0.81942445 103.929756\n",
      "  78.187996     0.           0.         158.92886      0.\n",
      "  75.38312      0.          78.04417     93.01987     16.88218\n",
      "   0.         187.74965      0.         177.41753     78.87956\n",
      " 135.73222     45.639744     1.8851217    0.         219.65024\n",
      "   0.         174.57637     31.986315   158.40813     40.542923\n",
      "   0.           0.         163.01465      0.          99.903114\n",
      "   0.         127.931404    24.70409      3.1620286    0.\n",
      "  85.551476     0.          74.60562     21.182499    61.64578\n",
      "  27.218506     0.           0.          78.79623      0.\n",
      "  59.812084    14.18143     55.095863    74.70435      0.\n",
      "   0.         149.25264      0.         112.51681     17.26467\n",
      "  89.907364    42.608044     0.           0.         181.18626\n",
      "   0.         101.66399      0.         113.7718      49.017788\n",
      "   0.           0.         167.09772      0.          90.28553\n",
      "   0.          92.71146     71.104126    16.467056     0.\n",
      " 133.74168      0.         146.7094      78.288246    76.31368\n",
      "  48.947407     8.085408     0.         203.80637      0.\n",
      " 172.47214     37.04448    157.13048     34.908928    11.255907\n",
      "   0.         151.17088      0.         156.52107     67.12974\n",
      " 129.09009     40.262207     2.4757562    0.         134.03368\n",
      "   0.         113.54788      8.113485   114.67915     44.99818\n",
      "   0.           0.         125.6714       0.          70.498215\n",
      "   0.5705138   86.23934     74.14821      0.           0.\n",
      " 190.21892      0.         197.25783     41.107147   148.55692\n",
      "  50.81351      0.           0.         211.90395      0.\n",
      " 189.98853     19.690096   169.8346      68.010284     0.\n",
      "   0.         227.21227      0.         207.56702     38.07716\n",
      " 178.46606     96.42088      3.5251865    0.         226.2769\n",
      "   0.         168.94287     38.25625    170.69818     57.113354\n",
      "   3.2942762    0.         203.79236      0.         171.64914\n",
      "  26.484459   151.88712     27.849138    11.615117     0.\n",
      " 136.23131      0.         150.22531     55.562614   119.65503\n",
      "  27.044641     8.060335     0.         149.29568      0.\n",
      " 155.10054     51.65952    122.0739      20.795996     0.\n",
      "   0.         144.39575      0.         122.83898     27.08456\n",
      " 112.36031     70.95404      1.2083054    0.         276.95477\n",
      "   0.         231.31224     52.074368   193.56476     63.551098\n",
      "   0.           0.         240.3996       0.         224.35452\n",
      "  57.643753   183.46913     55.92729      0.           0.\n",
      " 242.21048      0.         198.69936     54.254242   171.63457\n",
      "  67.53949      0.           0.         251.21738      0.\n",
      " 202.41219     27.274094   174.28886     58.523228     8.379363\n",
      "   0.         241.54883      0.         182.65302     18.749247\n",
      " 165.86023     29.997952    10.1481495    0.         139.1195\n",
      "   0.         170.64444     62.199207   136.94106     34.347034\n",
      "   7.6709204    0.         142.44067      0.         173.79877\n",
      "  51.497154   140.297       25.944763     0.           0.\n",
      " 156.56923      0.         154.77911     38.41999    124.63267\n",
      "  37.402874     0.           0.         188.6212       0.\n",
      " 107.30332      0.         123.9625      65.441124     0.\n",
      "   0.         160.18144      0.         129.2075      29.35276\n",
      " 112.71752    101.10488      5.180106     0.         227.7425\n",
      "   0.         152.05142     55.172306   133.00142     75.44771\n",
      "   0.           0.         223.63263      0.         169.23834\n",
      "  57.949318   150.64896     55.49817      7.447495     0.\n",
      " 198.25732      0.         147.20241     45.450897   135.40536\n",
      "  74.835236     8.0870905    0.         164.62573      0.\n",
      " 139.48636     76.15349    104.41308     45.403038    10.573694\n",
      "   0.         156.29759      0.         181.11308     61.367558\n",
      " 147.68506     31.38565      0.           0.         182.03673\n",
      "   0.         161.257       67.064865   140.14502     47.48215\n",
      "   0.           0.         175.2867       0.         143.81015\n",
      "  25.13522    122.91853     70.97637      2.513088     0.\n",
      " 189.01056      0.         141.11496     24.526058   133.38448\n",
      "  49.173042     0.           0.         185.39047      0.\n",
      " 146.36525     26.429672   128.5957      24.338806     0.\n",
      "   0.         116.14052      0.          76.434586    10.200859\n",
      "  89.55728     83.486565     6.804088     0.         115.704956\n",
      "   0.          71.13222     18.600422    77.808556    29.375217\n",
      "   0.           0.         110.446724     0.          79.453255\n",
      "  15.470309    68.75761     53.252502     0.           0.\n",
      "  89.653786     0.          83.428894    25.988392    72.413216\n",
      "  79.807304     4.5315213    0.         117.90997      0.\n",
      "  84.92314     43.4207      76.811295    61.29922      4.6982355\n",
      "  21.32035    197.92206      0.         156.57031     72.777725\n",
      " 122.17003     26.229969     6.465784    34.143566   166.53204\n",
      "   0.         139.13603     74.53576    111.41573     32.51282\n",
      "   7.2815657   30.187695   162.08823      0.         151.58992\n",
      "  70.550476   120.261406    46.832184     0.           5.7048893\n",
      " 111.56677      0.          90.506676    22.758028    65.587616\n",
      "  28.243694     0.           3.8035717  102.49881      0.\n",
      "  53.714455    14.314245    67.22421     39.80743      5.0199466\n",
      "  32.265434    88.69997      0.          98.7866      62.56327\n",
      "  66.6753      31.927042     1.5976235   31.531015   143.39638\n",
      "   0.         125.58204     65.42092    115.73221     45.09752\n",
      "   4.1644025   23.707191   153.48578      0.         118.89492\n",
      "  72.61737    100.13825   ]\n"
     ]
    }
   ],
   "source": [
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "004b513b-dee6-477b-b7a5-e463ca964b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13.862544    14.950963     0.          67.28831      0.\n",
      "  89.52783     58.406456    61.56639     17.7618      10.0758\n",
      "   0.         107.9237       0.         101.77234     52.808384\n",
      "  80.089195    11.62138     10.526963     0.         103.072014\n",
      "   0.         100.64986     55.43944     79.60229      6.350231\n",
      "   6.716766     0.         104.08884      0.          94.10237\n",
      "  46.45564     87.55301      5.4538713    7.3767576    0.\n",
      "  97.75872      0.          99.92352     47.637486    78.77121\n",
      "  15.598895    11.029854     0.         108.19276      0.\n",
      " 108.25096     62.37186     87.24896     10.566191     7.516699\n",
      "   0.         115.85992      0.         108.86381     57.064243\n",
      "  90.218575     7.802604     0.           0.         125.28652\n",
      "   0.          98.84879     42.627308    90.30014     15.9485445\n",
      "  12.499206     0.          84.75455      0.          98.74079\n",
      "  51.255264    82.23799      4.657741     7.2165494    0.\n",
      "  74.47747      0.          92.197495    46.12319     78.0116\n",
      "  15.3274555    5.1996555    0.          85.04816      0.\n",
      "  85.41855     36.316265    79.53734      5.305396    25.370901\n",
      "   0.          84.52188      0.         137.61465     98.204216\n",
      "  84.31423     26.839998    11.60513      0.         114.5433\n",
      "   0.          91.567215    62.86661    123.284676     1.911138\n",
      "  10.842883     0.          91.26538      0.          97.96524\n",
      "  58.684315    88.58516      4.5381937    6.2719536    0.\n",
      "  86.2871       0.          82.66399     35.320004    83.62373\n",
      "   0.           0.92698133   0.          71.545616     0.\n",
      "  76.86781     30.1651      66.61387     10.900633     7.143798\n",
      "   0.         101.646355     0.         109.72552     42.693737\n",
      "  93.40261     20.818415     8.265984     0.         101.75774\n",
      "   0.         102.24385     42.940174    82.9783      23.441736\n",
      "  10.602463     0.         101.714294     0.         137.33466\n",
      "  56.943665   101.175446    37.453136    23.019892     0.\n",
      "  86.59577      0.         137.30745     89.72644    123.64078\n",
      "  33.082645    11.780367     0.         116.197        0.\n",
      " 143.54161     65.709755   107.002655    31.596298    12.016845\n",
      "   0.         122.52869      0.         102.81354     46.136105\n",
      " 114.298744     4.4008904    7.274477     0.          80.68787\n",
      "   0.          91.82619     43.07924     80.45599      3.8777797\n",
      "   2.1156585    0.          82.56448      0.          89.09605\n",
      "  38.095318    79.11286     12.11962      7.250669     0.\n",
      "  99.12556      0.         101.78906     46.097767    89.691055\n",
      "  33.958504    16.138737     0.          82.30505      0.\n",
      " 154.9591      91.38416     80.255585    55.22688     19.705643\n",
      "   0.         159.97365      0.         168.99005     91.16364\n",
      " 136.15059     41.587105     5.3667617    0.         198.439\n",
      "   0.         209.35533     84.92464    165.21135     54.835693\n",
      "   6.8229537    0.         202.64587      0.         194.98047\n",
      "  44.46679    169.02484     52.113575     4.83338      0.\n",
      " 184.661        0.         183.4525      82.11549    149.80112\n",
      "  32.220036     7.29227      0.         125.05891      0.\n",
      " 111.008125    42.230392   114.64454     11.249432     1.2949921\n",
      "   0.          88.26728      0.          90.86297     38.80392\n",
      "  80.1041       7.0077205   12.166674     0.          87.75113\n",
      "   0.         119.43905     66.09805     84.41515     74.255264\n",
      "  20.656612     0.         219.77592      0.         213.00502\n",
      " 122.3935     167.1488      39.9457      11.343844     0.\n",
      " 196.43236      0.         191.7291      96.53554    161.96086\n",
      "  55.078857     7.4257293    0.         209.42844      0.\n",
      " 195.76183     65.428856   150.85124     21.735708    16.744207\n",
      "   0.         181.36092      0.         165.54562    108.65032\n",
      " 142.19379     53.031963    12.349368     0.         195.07576\n",
      "   0.         201.98698     78.04628    166.0489      15.207001\n",
      "   5.8028855    0.         142.38866      0.          99.5856\n",
      "  47.018143   119.1965       5.482156     0.           0.\n",
      "  95.73874      0.          94.681595    37.02913     78.885376\n",
      "  41.691227    19.255629     0.          99.78905      0.\n",
      " 127.52025     84.20914     90.04217     35.880444    17.598732\n",
      "   0.         167.1872       0.         158.23279    104.80734\n",
      " 126.79651     29.46479     10.986451     0.         136.09471\n",
      "   0.         171.2832      75.31815    142.3081      29.766068\n",
      "  10.109039     0.         133.36249      0.         132.01442\n",
      "  56.477245   144.11264     44.622906    18.802807     0.\n",
      " 106.03982      0.         134.49673     88.06092     90.912994\n",
      "  10.712119     9.121004     0.         151.81812      0.\n",
      " 135.98697     71.99774    111.19852     22.832111    11.693255\n",
      "   0.          93.04147      0.          97.77779     39.96609\n",
      "  95.272934    44.411324     0.           0.         123.59934\n",
      "   0.         125.42217     48.35754     96.67879     21.119698\n",
      "   8.234136     0.          98.92644      0.         103.899254\n",
      "  52.989597   107.047844    14.733735    11.337706     0.\n",
      " 107.75139      0.         117.75344     64.63766     91.12726\n",
      "  30.47971     14.609983     0.         150.39503      0.\n",
      " 133.82788     83.50723    101.01413      4.6490965    9.987411\n",
      "   0.         156.33212      0.         106.128044    54.69084\n",
      " 113.572914    15.504841    10.328533     0.          92.74911\n",
      "   0.         106.42745     54.485638    92.67715     10.219367\n",
      "   8.518259     0.          91.66496      0.         101.560394\n",
      "  48.05693     88.70034     33.09023     17.009272     0.\n",
      " 117.37199      0.         144.3266      76.607956   102.68295\n",
      "  23.498009     0.           0.         172.28987      0.\n",
      " 127.108406    27.132479   121.73421     24.86655     11.360768\n",
      "  42.969364   156.38103      0.         173.36008     93.83316\n",
      " 147.6106      50.23019     14.897058    32.136173   167.08128\n",
      "   0.         186.87077     83.457664   145.48116     32.023754\n",
      "  11.04838     27.602875   135.902        0.         158.93704\n",
      "  67.50165    133.91675     37.44707     11.003129    27.395025\n",
      " 126.76779      0.         154.08922     66.38691    128.32011\n",
      "  29.352787    11.595778    24.178328   117.0287       0.\n",
      " 152.44188     60.384296   123.15838     27.452053     9.1131735\n",
      "  21.216295   101.46893      0.         130.27237     52.69319\n",
      " 113.42484     46.251133    15.152869    52.801105   139.65216\n",
      "   0.         174.5212     110.19697    123.846       41.86401\n",
      "   0.           0.         150.45232      0.         103.255745\n",
      "  41.11293    147.20505   ]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6091d580-da1a-44c2-bc7e-4bb24bc98d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define and train the model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a4d92-2928-4e68-ac47-c70f4d78781b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
