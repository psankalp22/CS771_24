{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932b7e50-1dfd-41cf-8262-3c6481881b07",
   "metadata": {},
   "source": [
    "## ignoring warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca764d97-d738-4ca6-8f35-ff180ea5e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07d70df-6c69-4f9f-99f6-187a900aab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e1431-5625-4e33-b9cf-8fc1a6ea1f4c",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9c220d-fa56-4b60-a2bb-f3a4c3f4c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.load('../dataset/dataset/part_one_dataset/train_data/1_train_data.tar.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d063a-f6b2-49d6-a576-f0ee4e60197b",
   "metadata": {},
   "source": [
    "## Analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39512559-c29e-4b37-b5e3-ff3605f71cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'targets'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34fa842-ec9f-49b1-971d-904e79fee36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 32, 32, 3)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "print(data['data'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3634371-e639-4c7a-a4c4-f0761ae36de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3275f45e-eec4-457c-bcea-ad7f5094b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data['data'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04cb2040-71ab-42bd-a35e-eae62c1d0233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284106d8-8076-46a9-a127-e399ca9c9e9f",
   "metadata": {},
   "source": [
    "## Converting dict to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4047b0a2-4aa2-4a8e-b600-ba7e54f741f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['targets']))\n",
    "print(type(data['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7163e980-9a6e-4330-9394-d48d9c572333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500,)\n",
      "(2500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data['targets'].shape)\n",
    "print(data['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb6f1c26-9d37-4bc7-9b83-7c23efea4ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   targets\n",
      "0        6\n",
      "1        9\n",
      "2        9\n",
      "3        4\n",
      "4        1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data['targets'])\n",
    "df.columns = ['targets']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f38be8-c2da-41f9-b020-7fb812942b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f025950-82d2-4b38-97eb-978f7cbf4f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='targets', ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='targets', data=df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf53e6-8b8e-4fda-be3d-3c068c59a153",
   "metadata": {},
   "source": [
    "## Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a26b4d-1b9e-4c06-bf3b-39dcde1cc419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Extracted Features Shape: (2500, 15, 15, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "X_train = data['data']  # 2500 images, 32x32x3 shape\n",
    "y_train = data['targets']   # 10 classes (0-9)\n",
    "\n",
    "# Create a CNN model for feature extraction\n",
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "# Convolutional Layer 1\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Convolutional Layer 2\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Flatten the output of the last convolutional layer\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Fully connected layers (optional for classification)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Build the model\n",
    "cnn_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Perform a dummy pass to initialize the model and its weights\n",
    "cnn_model.predict(np.random.rand(1, 32, 32, 3))  # A dummy pass to initialize the model\n",
    "\n",
    "# Now, remove the classification layers and only output the features\n",
    "# Access the last convolutional layer (before flattening) for feature extraction\n",
    "feature_extractor = Model(inputs=cnn_model.input, outputs=cnn_model.layers[2].output)  # The second conv layer is at index 2\n",
    "\n",
    "# Extract features from the CNN model (this will be a 2D array of shape (2500, num_features))\n",
    "features = feature_extractor.predict(X_train)\n",
    "\n",
    "print(f\"Extracted Features Shape: {features.shape}\")  # Should print the shape like (2500, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b829c98-1985-4a2d-bc25-f47f484e91ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2e909-c43b-4b21-a1cc-1d557ea97d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac5dea-c65d-414d-b5ea-5a7745642a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b52ccf9-c63c-4b5d-abfe-86dbed815d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 7200)\n"
     ]
    }
   ],
   "source": [
    "features_flat = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Now, 'features_flat' contains the extracted features\n",
    "print(features_flat.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffaa002-f80b-4d5e-867a-e3d03ade6026",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1bbcb0-d58c-4fa1-b2ee-bd90cda9e48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 197)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assume features_flat is your flattened feature array from the pretrained model\n",
    "# For example, features_flat.shape = (2500, 25088) for VGG16\n",
    "\n",
    "# Initialize PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "features_reduced = pca.fit_transform(features_flat)\n",
    "\n",
    "print(features_reduced.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99abe3ce-2411-4a2b-9ea4-747a3e543c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(features_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc79f07-e636-4124-b597-8196584948b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.42133484e+02  3.19530884e+02  3.99988098e+02 -6.81166077e+01\n",
      " -1.71152374e+02  2.86264069e+02 -4.77543640e+02 -9.45908585e+01\n",
      "  3.64191162e+02 -2.67274837e+01 -9.31042938e+01 -1.70824871e+01\n",
      " -1.42273315e+02  2.69070644e+01 -1.34924774e+02 -1.67679962e+02\n",
      " -8.23179855e+01  7.41216354e+01  1.09428474e+02 -1.01316330e+02\n",
      "  5.59224548e+01 -5.76007996e+01 -8.19527969e+01 -1.66649647e+01\n",
      " -2.05370850e+02 -3.58563194e+01  6.30970535e+01 -5.09900703e+01\n",
      "  1.42064590e+02 -5.57907486e+01 -1.23121691e+01 -2.05236649e+02\n",
      "  6.86222076e+01 -7.81656494e+01 -2.18883681e+00 -1.33190399e+02\n",
      "  2.92115364e+01 -2.77154102e+01 -8.24711075e+01  6.50013733e+01\n",
      " -2.97441082e+01 -1.17397369e+02 -6.14591675e+01  1.24727039e+01\n",
      "  2.63783741e+01 -4.41545792e+01 -7.97813644e+01 -1.34584686e+02\n",
      "  8.28263855e+01  1.25009813e+01  3.81719551e+01 -6.55501862e+01\n",
      "  4.76214561e+01 -1.96647930e+01  8.48361740e+01 -8.61513710e+00\n",
      "  2.76693511e+00 -6.77118530e+01 -2.58052635e+01 -1.84278107e+01\n",
      " -2.33583713e+00  4.85496864e+01 -9.47273941e+01  1.54697540e+02\n",
      " -9.95276546e+00 -3.15995827e+01  1.06796761e+02  4.14097137e+01\n",
      "  2.51515312e+01 -4.22293739e+01  1.19734116e+01  1.63145123e+01\n",
      "  1.02778084e+02 -2.92477589e+01  2.68707466e+01  3.39429283e+01\n",
      "  1.68369446e+01 -4.75399437e+01 -8.99373245e+01  2.73669300e+01\n",
      " -3.98720207e+01  2.01837578e+01 -1.77803936e+01 -2.24268551e+01\n",
      "  8.08118973e+01 -2.86015396e+01  1.01077871e+01  2.11644440e+01\n",
      " -4.96850395e+01  8.17665195e+00  3.25362358e+01  3.23262501e+00\n",
      " -2.70567760e+01 -1.23619623e+01 -1.00508964e+00  7.37011490e+01\n",
      " -1.48120947e+01 -4.11462927e+00  1.18968575e+02 -1.38106651e+01\n",
      "  3.73816156e+00 -3.84613533e+01 -1.23501492e+01  2.30173302e+01\n",
      " -1.95522938e+01  5.82060318e+01 -7.42760620e+01 -7.32484818e+01\n",
      "  4.07016068e+01 -3.30311852e+01 -1.00661926e+02  2.28728390e+01\n",
      " -3.74547119e+01  8.51098537e+00 -2.78855209e+01 -1.61710224e+01\n",
      "  4.10376511e+01 -1.89496078e+01 -6.99206305e+00  3.83178711e+01\n",
      "  1.08742161e+01  1.58897257e+01  1.00311251e+01 -1.83496094e+01\n",
      " -2.34091015e+01 -3.65820236e+01  2.40460472e+01  3.29078603e+00\n",
      "  3.65488625e+01  5.02730322e+00 -2.78857822e+01  4.80203857e+01\n",
      "  6.77627802e+00 -4.18261032e+01 -3.73221326e+00 -1.36409664e+00\n",
      " -1.62454453e+01  2.14220562e+01  4.88121796e+01  6.02713633e+00\n",
      " -2.86937976e+00  3.93387146e+01  4.93581200e+01  3.08941040e+01\n",
      "  3.35038757e+01  6.02941246e+01  4.58177490e+01 -7.30391312e+00\n",
      "  1.59957874e+00 -3.63818359e+01 -3.75245514e+01 -9.89154339e+00\n",
      " -1.50014791e+01 -2.31812382e+01 -7.69130421e+00 -3.58902931e+01\n",
      " -4.06528931e+01  3.53420105e+01 -1.11859770e+01  1.26005096e+01\n",
      " -1.26733434e+00 -3.20998383e+01 -2.47451496e+01 -3.65161467e+00\n",
      "  6.43486023e+01 -1.34071798e+01  1.13425941e+01 -1.77184906e+01\n",
      "  9.35938299e-01  2.27360058e+01  2.97417974e+00 -5.56344299e+01\n",
      "  9.20610332e+00 -6.69328308e+00  1.31492653e+01 -3.37295036e+01\n",
      " -1.44504175e+01  1.35715733e+01 -1.03852329e+01  4.08675880e+01\n",
      " -8.80479336e+00  1.89632702e+00 -1.89486504e+01 -3.47173920e+01\n",
      "  2.94251652e+01 -1.53054342e+01  2.28772902e+00  1.69616508e+01\n",
      "  2.11589756e+01  3.25142822e+01 -6.00173569e+01  3.60369949e+01\n",
      " -4.72860098e+00  9.82867622e+00  4.87585564e+01  2.06231365e+01\n",
      " -1.17703638e+01]\n"
     ]
    }
   ],
   "source": [
    "print(features_reduced[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bef4ed-13e4-44d7-9630-2f25bed36f81",
   "metadata": {},
   "source": [
    "## Converting to Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76cb619c-86dd-454a-8859-d793e9a7614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 197)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the reduced feature set (features_reduced)\n",
    "features_standardized = scaler.fit_transform(features_reduced)\n",
    "\n",
    "# Now, 'features_standardized' is standardized and ready for use\n",
    "\n",
    "print(features_standardized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca0ba307-6cd0-4434-bf5c-f35eefaf7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(features_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "604d8b74-6880-495b-8664-b8bb4012b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   targets\n",
      "0        6\n",
      "1        9\n",
      "2        9\n",
      "3        4\n",
      "4        1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f180cf6-310c-4f53-9396-314c9648fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -1.042991  0.571573  0.884869 -0.204003 -0.600631  1.037739 -1.789148   \n",
      "1  0.501430  0.183479  1.719059  1.187633 -0.462665  0.581864 -0.280496   \n",
      "2  0.924249 -2.615865 -0.451526  1.114430  1.116076  0.125959 -0.084454   \n",
      "3 -1.520514 -0.045934  0.457797 -0.061853 -0.485933  0.575733 -0.599495   \n",
      "4 -0.204705 -0.624791  0.716081  0.766009 -1.634096  2.184205  1.818732   \n",
      "\n",
      "          7         8         9  ...       188       189       190       191  \\\n",
      "0 -0.371739  1.502126 -0.130588  ...  0.791479  1.218074 -2.266400  1.371203   \n",
      "1 -0.204404  1.000061  0.186951  ... -1.093575 -0.155285  0.614136  0.976716   \n",
      "2  0.552628  0.167483 -0.792693  ...  0.764892  1.206972 -0.018604 -0.022671   \n",
      "3 -0.218466  0.712605 -0.019918  ... -0.276307 -0.962911 -0.752052 -0.511022   \n",
      "4 -1.114561  0.697149  2.362626  ... -0.036335  1.262264  1.050442  2.919211   \n",
      "\n",
      "        192       193       194       195       196  targets  \n",
      "0 -0.180558  0.377833  1.885254  0.799572 -0.456843        6  \n",
      "1 -1.329507  0.626491  1.335926  2.232019 -3.779245        9  \n",
      "2  0.727046 -0.382667 -0.218901  0.554379 -0.107290        9  \n",
      "3 -0.733375 -0.266890 -0.452542 -0.668515  0.429064        4  \n",
      "4  0.155794  0.058279 -0.582589  0.202348 -0.383047        1  \n",
      "\n",
      "[5 rows x 198 columns]\n"
     ]
    }
   ],
   "source": [
    "df_concat = pd.concat([df_data,df],axis = 1)\n",
    "print(df_concat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48358dff-ae8e-4ed2-835e-403d6cbb06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0429906   0.5715735   0.8848693  ...  1.885254    0.7995722\n",
      "  -0.4568425 ]\n",
      " [ 0.50143033  0.18347883  1.7190593  ...  1.335926    2.2320187\n",
      "  -3.7792451 ]\n",
      " [ 0.92424923 -2.6158655  -0.4515261  ... -0.21890102  0.55437917\n",
      "  -0.10729046]\n",
      " ...\n",
      " [ 0.03987663 -1.3399388  -0.25572163 ... -1.82035     0.7325198\n",
      "  -1.0288762 ]\n",
      " [ 1.0451206  -1.5756922   0.08399402 ... -0.39443403 -1.1628679\n",
      "   1.1637527 ]\n",
      " [ 0.22680488  0.40716994  1.8048841  ... -0.382586    0.32030252\n",
      "   0.02561782]]\n"
     ]
    }
   ],
   "source": [
    "print((features_standardized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65920f46-9e22-438b-a202-9d59caf0885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['targets']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f28de-edf1-477a-8545-d38b512fa665",
   "metadata": {},
   "source": [
    "## DO the lwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7de1c901-773c-4194-ad7a-9b556dda8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = data['targets']\n",
    "X = features_standardized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d12788b7-5363-44a5-81d3-687a19ebd2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.0924 - loss: 3.6638 - val_accuracy: 0.2140 - val_loss: 2.2649\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3624 - loss: 2.0406 - val_accuracy: 0.3220 - val_loss: 1.9715\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6102 - loss: 1.4479 - val_accuracy: 0.3940 - val_loss: 1.7114\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7730 - loss: 0.8662 - val_accuracy: 0.4400 - val_loss: 1.6686\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8788 - loss: 0.5272 - val_accuracy: 0.4340 - val_loss: 1.7637\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.3018 - val_accuracy: 0.4380 - val_loss: 1.8792\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.1890 - val_accuracy: 0.4200 - val_loss: 2.0101\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.1013 - val_accuracy: 0.4240 - val_loss: 2.1364\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0606 - val_accuracy: 0.4260 - val_loss: 2.2431\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0448 - val_accuracy: 0.4200 - val_loss: 2.3391\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0275 - val_accuracy: 0.4200 - val_loss: 2.4208\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.4160 - val_loss: 2.5036\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.4240 - val_loss: 2.5684\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.4180 - val_loss: 2.6331\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.4140 - val_loss: 2.6902\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.4140 - val_loss: 2.7346\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.4140 - val_loss: 2.7840\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.4140 - val_loss: 2.8276\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.4140 - val_loss: 2.8688\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.4160 - val_loss: 2.9009\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.4160 - val_loss: 2.9399\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.4180 - val_loss: 2.9703\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.4160 - val_loss: 3.0042\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4180 - val_loss: 3.0350\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.4160 - val_loss: 3.0632\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.4160 - val_loss: 3.0893\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.4160 - val_loss: 3.1162\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.4160 - val_loss: 3.1427\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.4160 - val_loss: 3.1674\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.4160 - val_loss: 3.1915\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.4160 - val_loss: 3.2149\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.4180 - val_loss: 3.2374\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.6088e-04 - val_accuracy: 0.4180 - val_loss: 3.2592\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8954e-04 - val_accuracy: 0.4180 - val_loss: 3.2803\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.9724e-04 - val_accuracy: 0.4200 - val_loss: 3.3003\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.0048e-04 - val_accuracy: 0.4200 - val_loss: 3.3221\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.0487e-04 - val_accuracy: 0.4200 - val_loss: 3.3424\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7327e-04 - val_accuracy: 0.4200 - val_loss: 3.3611\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.2565e-04 - val_accuracy: 0.4200 - val_loss: 3.3800\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.1858e-04 - val_accuracy: 0.4200 - val_loss: 3.4004\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.5362e-04 - val_accuracy: 0.4180 - val_loss: 3.4178\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1573e-04 - val_accuracy: 0.4200 - val_loss: 3.4371\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1494e-04 - val_accuracy: 0.4180 - val_loss: 3.4543\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4317e-04 - val_accuracy: 0.4180 - val_loss: 3.4719\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.2842e-04 - val_accuracy: 0.4200 - val_loss: 3.4893\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.0687e-04 - val_accuracy: 0.4200 - val_loss: 3.5053\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.8323e-04 - val_accuracy: 0.4200 - val_loss: 3.5226\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.5486e-04 - val_accuracy: 0.4180 - val_loss: 3.5386\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.2727e-04 - val_accuracy: 0.4200 - val_loss: 3.5555\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.1543e-04 - val_accuracy: 0.4180 - val_loss: 3.5709\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.9747e-04 - val_accuracy: 0.4180 - val_loss: 3.5868\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.8953e-04 - val_accuracy: 0.4180 - val_loss: 3.6021\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.6324e-04 - val_accuracy: 0.4180 - val_loss: 3.6176\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.6493e-04 - val_accuracy: 0.4160 - val_loss: 3.6318\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.4770e-04 - val_accuracy: 0.4160 - val_loss: 3.6477\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3638e-04 - val_accuracy: 0.4160 - val_loss: 3.6625\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.2186e-04 - val_accuracy: 0.4160 - val_loss: 3.6774\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.1515e-04 - val_accuracy: 0.4160 - val_loss: 3.6915\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.9767e-04 - val_accuracy: 0.4160 - val_loss: 3.7053\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.9170e-04 - val_accuracy: 0.4140 - val_loss: 3.7205\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7475e-04 - val_accuracy: 0.4140 - val_loss: 3.7339\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6869e-04 - val_accuracy: 0.4140 - val_loss: 3.7478\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5963e-04 - val_accuracy: 0.4140 - val_loss: 3.7622\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4936e-04 - val_accuracy: 0.4140 - val_loss: 3.7753\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4332e-04 - val_accuracy: 0.4140 - val_loss: 3.7896\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.3471e-04 - val_accuracy: 0.4140 - val_loss: 3.8027\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.3007e-04 - val_accuracy: 0.4140 - val_loss: 3.8171\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2752e-04 - val_accuracy: 0.4140 - val_loss: 3.8306\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2594e-04 - val_accuracy: 0.4140 - val_loss: 3.8434\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.1562e-04 - val_accuracy: 0.4140 - val_loss: 3.8555\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0939e-04 - val_accuracy: 0.4100 - val_loss: 3.8695\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0615e-04 - val_accuracy: 0.4120 - val_loss: 3.8818\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0127e-04 - val_accuracy: 0.4120 - val_loss: 3.8953\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.7442e-05 - val_accuracy: 0.4100 - val_loss: 3.9078\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.4819e-05 - val_accuracy: 0.4120 - val_loss: 3.9210\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.8172e-05 - val_accuracy: 0.4120 - val_loss: 3.9340\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.3839e-05 - val_accuracy: 0.4120 - val_loss: 3.9456\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.9555e-05 - val_accuracy: 0.4120 - val_loss: 3.9587\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.8324e-05 - val_accuracy: 0.4120 - val_loss: 3.9707\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.6525e-05 - val_accuracy: 0.4100 - val_loss: 3.9833\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.2392e-05 - val_accuracy: 0.4120 - val_loss: 3.9954\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.4934e-05 - val_accuracy: 0.4100 - val_loss: 4.0073\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7048e-05 - val_accuracy: 0.4100 - val_loss: 4.0204\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.0740e-05 - val_accuracy: 0.4100 - val_loss: 4.0328\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.0128e-05 - val_accuracy: 0.4100 - val_loss: 4.0449\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9752e-05 - val_accuracy: 0.4100 - val_loss: 4.0565\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.3659e-05 - val_accuracy: 0.4100 - val_loss: 4.0676\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.4728e-05 - val_accuracy: 0.4100 - val_loss: 4.0800\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1656e-05 - val_accuracy: 0.4100 - val_loss: 4.0920\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.0922e-05 - val_accuracy: 0.4100 - val_loss: 4.1040\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.7646e-05 - val_accuracy: 0.4100 - val_loss: 4.1164\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.4042e-05 - val_accuracy: 0.4100 - val_loss: 4.1282\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.4640e-05 - val_accuracy: 0.4100 - val_loss: 4.1398\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1497e-05 - val_accuracy: 0.4100 - val_loss: 4.1510\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0802e-05 - val_accuracy: 0.4120 - val_loss: 4.1632\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.8849e-05 - val_accuracy: 0.4120 - val_loss: 4.1739\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6721e-05 - val_accuracy: 0.4140 - val_loss: 4.1851\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6469e-05 - val_accuracy: 0.4140 - val_loss: 4.1974\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.5011e-05 - val_accuracy: 0.4140 - val_loss: 4.2087\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.3497e-05 - val_accuracy: 0.4140 - val_loss: 4.2204\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "Validation Accuracy: 41.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example: X is your input data (already transformed, standardized, and linearized)\n",
    "# y is your labels (integers from 0 to 9 for 10 classes)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data to fit LSTM input requirements (LSTM expects 3D input)\n",
    "# Here, we reshape X_train and X_test from shape (num_samples, num_features) to (num_samples, timesteps, features)\n",
    "# We can consider each feature as a timestep, with 1 feature per timestep (timesteps=1).\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))  # (num_samples, timesteps=1, num_features)\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))      # (num_samples, timesteps=1, num_features)\n",
    "\n",
    "# Build the neural network model with an LSTM layer\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (since X has already been transformed, we start with the feature size directly)\n",
    "model.add(LSTM(128, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), activation='relu', return_sequences=False))  # LSTM layer\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(128, activation='relu'))  # Second hidden layer\n",
    "model.add(Dense(64, activation='softmax'))  # Output layer with 10 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Get the predicted class (the class with the highest probability)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91321ed-2dbe-4e9e-a84a-2b20396d2beb",
   "metadata": {},
   "source": [
    "### Analyzing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d954061a-93b4-4607-980d-c3dc5163fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89984fa9-8278-4d05-8f79-0d7c36377bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2500):\n",
    "    img = Image.fromarray(data['data'][i])\n",
    "    target_dir = f\"./{data['targets'][i]}\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    img.save(f\"{target_dir}/img{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72dd15-ad93-4c59-ba23-553b54d6e14d",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ae71f-4108-4f59-b296-324de12f9a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │              \u001b[38;5;34m52\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,142</span> (262.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,142\u001b[0m (262.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,142</span> (262.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,142\u001b[0m (262.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.1003 - loss: 2.3114 - val_accuracy: 0.2040 - val_loss: 2.2510\n",
      "Epoch 2/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2071 - loss: 2.2199 - val_accuracy: 0.2120 - val_loss: 2.1395\n",
      "Epoch 3/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2726 - loss: 2.0882 - val_accuracy: 0.2820 - val_loss: 1.9954\n",
      "Epoch 4/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3215 - loss: 1.9279 - val_accuracy: 0.2920 - val_loss: 1.9173\n",
      "Epoch 5/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3629 - loss: 1.8195 - val_accuracy: 0.3400 - val_loss: 1.8653\n",
      "Epoch 6/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4010 - loss: 1.7350 - val_accuracy: 0.3200 - val_loss: 1.7970\n",
      "Epoch 7/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4296 - loss: 1.6637 - val_accuracy: 0.3660 - val_loss: 1.7170\n",
      "Epoch 8/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4528 - loss: 1.5746 - val_accuracy: 0.4020 - val_loss: 1.6853\n",
      "Epoch 9/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4677 - loss: 1.5140 - val_accuracy: 0.4060 - val_loss: 1.6476\n",
      "Epoch 10/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4994 - loss: 1.4480 - val_accuracy: 0.4040 - val_loss: 1.6963\n",
      "Epoch 11/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5218 - loss: 1.3871 - val_accuracy: 0.4140 - val_loss: 1.6289\n",
      "Epoch 12/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5371 - loss: 1.3320 - val_accuracy: 0.4180 - val_loss: 1.6215\n",
      "Epoch 13/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5426 - loss: 1.2912 - val_accuracy: 0.4080 - val_loss: 1.7123\n",
      "Epoch 14/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5623 - loss: 1.2760 - val_accuracy: 0.4220 - val_loss: 1.5848\n",
      "Epoch 15/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5942 - loss: 1.1925 - val_accuracy: 0.4280 - val_loss: 1.6400\n",
      "Epoch 16/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5838 - loss: 1.1880 - val_accuracy: 0.4520 - val_loss: 1.5944\n",
      "Epoch 17/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6226 - loss: 1.1132 - val_accuracy: 0.4280 - val_loss: 1.6404\n",
      "Epoch 18/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6271 - loss: 1.0657 - val_accuracy: 0.4440 - val_loss: 1.6426\n",
      "Epoch 19/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6580 - loss: 1.0332 - val_accuracy: 0.4460 - val_loss: 1.6182\n",
      "Epoch 20/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6701 - loss: 0.9779 - val_accuracy: 0.4280 - val_loss: 1.6286\n",
      "Epoch 21/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6943 - loss: 0.9329 - val_accuracy: 0.4200 - val_loss: 1.6943\n",
      "Epoch 22/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7005 - loss: 0.9086 - val_accuracy: 0.4400 - val_loss: 1.6338\n",
      "Epoch 23/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7211 - loss: 0.8445 - val_accuracy: 0.4340 - val_loss: 1.6249\n",
      "Epoch 24/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7185 - loss: 0.8173 - val_accuracy: 0.4360 - val_loss: 1.7330\n",
      "Epoch 25/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7294 - loss: 0.8181 - val_accuracy: 0.4300 - val_loss: 1.7343\n",
      "Epoch 26/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7429 - loss: 0.7709 - val_accuracy: 0.4120 - val_loss: 1.7909\n",
      "Epoch 27/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7698 - loss: 0.7246 - val_accuracy: 0.4260 - val_loss: 1.7618\n",
      "Epoch 28/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7792 - loss: 0.6960 - val_accuracy: 0.4260 - val_loss: 1.7071\n",
      "Epoch 29/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8195 - loss: 0.6269 - val_accuracy: 0.4400 - val_loss: 1.7958\n",
      "Epoch 30/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8311 - loss: 0.5934 - val_accuracy: 0.4400 - val_loss: 1.7681\n",
      "Epoch 31/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8475 - loss: 0.5564 - val_accuracy: 0.4240 - val_loss: 1.7780\n",
      "Epoch 32/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8519 - loss: 0.5473 - val_accuracy: 0.4320 - val_loss: 1.8243\n",
      "Epoch 33/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8562 - loss: 0.5216 - val_accuracy: 0.4120 - val_loss: 1.9551\n",
      "Epoch 34/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8447 - loss: 0.5131 - val_accuracy: 0.4180 - val_loss: 1.9129\n",
      "Epoch 35/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8675 - loss: 0.4685 - val_accuracy: 0.4340 - val_loss: 1.9295\n",
      "Epoch 36/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8938 - loss: 0.4107 - val_accuracy: 0.4180 - val_loss: 1.9801\n",
      "Epoch 37/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8897 - loss: 0.4091 - val_accuracy: 0.4520 - val_loss: 2.0402\n",
      "Epoch 38/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8994 - loss: 0.3938 - val_accuracy: 0.4120 - val_loss: 2.1355\n",
      "Epoch 39/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9191 - loss: 0.3571 - val_accuracy: 0.4180 - val_loss: 2.1748\n",
      "Epoch 40/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.3416 - val_accuracy: 0.4280 - val_loss: 2.1353\n",
      "Epoch 41/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9238 - loss: 0.3342 - val_accuracy: 0.4220 - val_loss: 2.1834\n",
      "Epoch 42/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9425 - loss: 0.2827 - val_accuracy: 0.4200 - val_loss: 2.1815\n",
      "Epoch 43/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.2729 - val_accuracy: 0.4160 - val_loss: 2.2294\n",
      "Epoch 44/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9501 - loss: 0.2541 - val_accuracy: 0.4160 - val_loss: 2.2950\n",
      "Epoch 45/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9519 - loss: 0.2297 - val_accuracy: 0.4220 - val_loss: 2.3199\n",
      "Epoch 46/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9610 - loss: 0.2101 - val_accuracy: 0.4280 - val_loss: 2.3661\n",
      "Epoch 47/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9585 - loss: 0.2068 - val_accuracy: 0.4120 - val_loss: 2.4203\n",
      "Epoch 48/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.1817 - val_accuracy: 0.4100 - val_loss: 2.4407\n",
      "Epoch 49/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9591 - loss: 0.1835 - val_accuracy: 0.3880 - val_loss: 2.5751\n",
      "Epoch 50/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9625 - loss: 0.1799 - val_accuracy: 0.4120 - val_loss: 2.5597\n",
      "Epoch 51/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9734 - loss: 0.1555 - val_accuracy: 0.4140 - val_loss: 2.6051\n",
      "Epoch 52/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.1508 - val_accuracy: 0.4160 - val_loss: 2.6002\n",
      "Epoch 53/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9803 - loss: 0.1269 - val_accuracy: 0.4300 - val_loss: 2.6755\n",
      "Epoch 54/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.1127 - val_accuracy: 0.4340 - val_loss: 2.7207\n",
      "Epoch 55/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.1062 - val_accuracy: 0.4180 - val_loss: 2.7539\n",
      "Epoch 56/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.1001 - val_accuracy: 0.4240 - val_loss: 2.7583\n",
      "Epoch 57/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0905 - val_accuracy: 0.4100 - val_loss: 2.8386\n",
      "Epoch 58/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0812 - val_accuracy: 0.4500 - val_loss: 2.8973\n",
      "Epoch 59/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0798 - val_accuracy: 0.4060 - val_loss: 2.9292\n",
      "Epoch 60/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.0856 - val_accuracy: 0.4320 - val_loss: 2.9675\n",
      "Epoch 61/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0705 - val_accuracy: 0.4260 - val_loss: 2.9913\n",
      "Epoch 62/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0611 - val_accuracy: 0.4100 - val_loss: 3.0755\n",
      "Epoch 63/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0511 - val_accuracy: 0.4100 - val_loss: 3.1179\n",
      "Epoch 64/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0508 - val_accuracy: 0.4220 - val_loss: 3.1190\n",
      "Epoch 65/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0506 - val_accuracy: 0.4200 - val_loss: 3.1403\n",
      "Epoch 66/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.0412 - val_accuracy: 0.4340 - val_loss: 3.1813\n",
      "Epoch 67/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0353 - val_accuracy: 0.4400 - val_loss: 3.2060\n",
      "Epoch 68/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 0.4360 - val_loss: 3.2269\n",
      "Epoch 69/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0381 - val_accuracy: 0.3980 - val_loss: 3.2971\n",
      "Epoch 70/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 0.4220 - val_loss: 3.2899\n",
      "Epoch 71/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0311 - val_accuracy: 0.4280 - val_loss: 3.3345\n",
      "Epoch 72/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 0.4320 - val_loss: 3.4122\n",
      "Epoch 73/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0263 - val_accuracy: 0.4200 - val_loss: 3.4208\n",
      "Epoch 74/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0251 - val_accuracy: 0.4060 - val_loss: 3.5080\n",
      "Epoch 75/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0232 - val_accuracy: 0.4060 - val_loss: 3.5117\n",
      "Epoch 76/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0210 - val_accuracy: 0.4200 - val_loss: 3.5110\n",
      "Epoch 77/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.4200 - val_loss: 3.5376\n",
      "Epoch 78/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.4300 - val_loss: 3.5578\n",
      "Epoch 79/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.4220 - val_loss: 3.5748\n",
      "Epoch 80/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.4160 - val_loss: 3.6197\n",
      "Epoch 81/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.4220 - val_loss: 3.6528\n",
      "Epoch 82/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.4140 - val_loss: 3.6680\n",
      "Epoch 83/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.4180 - val_loss: 3.7210\n",
      "Epoch 84/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.4180 - val_loss: 3.7383\n",
      "Epoch 85/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.4200 - val_loss: 3.7429\n",
      "Epoch 86/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.4180 - val_loss: 3.7810\n",
      "Epoch 87/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.4180 - val_loss: 3.8231\n",
      "Epoch 88/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.4240 - val_loss: 3.8165\n",
      "Epoch 89/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.4220 - val_loss: 3.8331\n",
      "Epoch 90/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.4240 - val_loss: 3.8904\n",
      "Epoch 91/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.4080 - val_loss: 3.8928\n",
      "Epoch 92/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.4200 - val_loss: 3.9051\n",
      "Epoch 93/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.4240 - val_loss: 3.9461\n",
      "Epoch 94/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.4200 - val_loss: 3.9541\n",
      "Epoch 95/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.4160 - val_loss: 3.9944\n",
      "Epoch 96/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.4180 - val_loss: 4.0053\n",
      "Epoch 97/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.4200 - val_loss: 4.0268\n",
      "Epoch 98/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.4160 - val_loss: 4.0509\n",
      "Epoch 99/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.4240 - val_loss: 4.0909\n",
      "Epoch 100/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.4080 - val_loss: 4.0916\n",
      "Epoch 101/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.4160 - val_loss: 4.1076\n",
      "Epoch 102/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.4180 - val_loss: 4.1305\n",
      "Epoch 103/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.4220 - val_loss: 4.1588\n",
      "Epoch 104/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.4220 - val_loss: 4.1782\n",
      "Epoch 105/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.4240 - val_loss: 4.1938\n",
      "Epoch 106/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.4100 - val_loss: 4.1980\n",
      "Epoch 107/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.4200 - val_loss: 4.2290\n",
      "Epoch 108/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.4200 - val_loss: 4.2480\n",
      "Epoch 109/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.4180 - val_loss: 4.2707\n",
      "Epoch 110/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.4200 - val_loss: 4.2925\n",
      "Epoch 111/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.4200 - val_loss: 4.3006\n",
      "Epoch 112/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.4240 - val_loss: 4.3197\n",
      "Epoch 113/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.4220 - val_loss: 4.3275\n",
      "Epoch 114/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.4280 - val_loss: 4.3482\n",
      "Epoch 115/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.4200 - val_loss: 4.3696\n",
      "Epoch 116/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.4180 - val_loss: 4.3916\n",
      "Epoch 117/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.4240 - val_loss: 4.4032\n",
      "Epoch 118/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.4200 - val_loss: 4.4217\n",
      "Epoch 119/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.4220 - val_loss: 4.4522\n",
      "Epoch 120/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.4220 - val_loss: 4.4389\n",
      "Epoch 121/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.4240 - val_loss: 4.4663\n",
      "Epoch 122/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.4220 - val_loss: 4.4844\n",
      "Epoch 123/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4240 - val_loss: 4.5168\n",
      "Epoch 124/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4220 - val_loss: 4.5259\n",
      "Epoch 125/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.4140 - val_loss: 4.5429\n",
      "Epoch 126/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4260 - val_loss: 4.5493\n",
      "Epoch 127/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4220 - val_loss: 4.5662\n",
      "Epoch 128/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4180 - val_loss: 4.5864\n",
      "Epoch 129/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4240 - val_loss: 4.6010\n",
      "Epoch 130/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.4240 - val_loss: 4.6178\n",
      "Epoch 131/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.4160 - val_loss: 4.6481\n",
      "Epoch 132/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.4300 - val_loss: 4.6334\n",
      "Epoch 133/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.4300 - val_loss: 4.6572\n",
      "Epoch 134/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.4280 - val_loss: 4.6690\n",
      "Epoch 135/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.4200 - val_loss: 4.6916\n",
      "Epoch 136/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.4280 - val_loss: 4.6909\n",
      "Epoch 137/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.4260 - val_loss: 4.7437\n",
      "Epoch 138/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.4260 - val_loss: 4.7364\n",
      "Epoch 139/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.4260 - val_loss: 4.7255\n",
      "Epoch 140/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.4200 - val_loss: 4.7500\n",
      "Epoch 141/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.4220 - val_loss: 4.7680\n",
      "Epoch 142/10000\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.4180 - val_loss: 4.7865\n",
      "Epoch 143/10000\n",
      "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `images` is a NumPy array or TensorFlow tensor with shape (num_samples, 32, 32, 3)\n",
    "images = data['data']  # Update with your actual dataset\n",
    "labels = data['targets']  # Ensure you have corresponding labels for supervised learning\n",
    "\n",
    "# Normalize the image data\n",
    "images = images / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Convert labels to one-hot encoding if not already\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=10)  # Adjust `num_classes` as per your dataset\n",
    "\n",
    "# Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Enhanced CNN Model for feature extraction\n",
    "model = tf.keras.Sequential([\n",
    "    # First Convolutional Block\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=4,  # Number of filters for learning low-level features\n",
    "        kernel_size=(2, 2),  # Filter size\n",
    "        strides=(1, 1),  # No down-sampling yet\n",
    "        padding='same',  # Keeps output size same\n",
    "        activation='relu',  # ReLU activation\n",
    "        input_shape=(32, 32, 3)  # Input shape for RGB images\n",
    "    ),\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),  # Reduce height and width by 2\n",
    "        strides=(2, 2),\n",
    "        padding='valid'  # Reduce size\n",
    "    ),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=8,  # Double the filters for learning mid-level features\n",
    "        kernel_size=(2, 2),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    ),\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=(2, 2),\n",
    "        padding='valid'\n",
    "    ),\n",
    "\n",
    "    # Flatten the features to use later or pass through Dense layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Add Dense layers for classification\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Adjust `10` to your number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10000,  # Train for 10000 epochs\n",
    "    batch_size=64,  # Adjust batch size as needed\n",
    "    verbose=1  # Use 1 for progress bar, 2 for one line per epoch\n",
    ")\n",
    "\n",
    "# Extract features using the model\n",
    "# Use intermediate layers or predictions for features\n",
    "features = model.predict(images)\n",
    "\n",
    "# Print feature shape\n",
    "print(f\"Extracted features shape: {features.shape}\")  # Example: (num_samples, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58611761-22a5-435e-b627-5c7f35e81c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assume features_flat is your flattened feature array from the pretrained model\n",
    "# For example, features_flat.shape = (2500, 25088) for VGG16\n",
    "\n",
    "# Initialize PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "features_reduced = pca.fit_transform(features)\n",
    "\n",
    "print(features_reduced.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781af6c8-e20d-484c-9c94-a6e8772f8c32",
   "metadata": {},
   "source": [
    "### Tsne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a66d60-327d-42aa-ace8-fb4aaac4d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387ef27-c22c-468f-882e-faccaaf2bb1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=4, random_state=42)\n",
    "features_2d = tsne.fit_transform(features)\n",
    "\n",
    "# Create a scatter plot where each class will have a different color\n",
    "# scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=y, cmap='jet', s=50, alpha=0.7)\n",
    "\n",
    "# # Add a color bar\n",
    "# plt.colorbar(scatter, label='Class')\n",
    "\n",
    "# # Set plot labels and title\n",
    "# plt.xlabel('t-SNE Component 1')\n",
    "# plt.ylabel('t-SNE Component 2')\n",
    "# plt.title('t-SNE visualization of high-dimensional data')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86214c0b-009e-4032-85e3-a7e10403ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_model = umap.UMAP(n_components=20, random_state=42)\n",
    "features_2d = umap_model.fit_transform(features)  # Apply UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83704096-cb84-4b9e-84c4-c994ce8ccd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d6507-8a70-4c93-8932-b1282ef341a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_2d\n",
    "y = data['targets']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c10365d-06e5-4504-975b-21e0d92e179c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6d060-e847-4edd-8e99-1cab1327ebf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af311477-f53e-48db-b1f6-868ddb30adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the input data (optional but recommended)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa8232-e296-4c96-858f-5299086d7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b513b-dee6-477b-b7a5-e463ca964b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add67f1-16ea-4abc-a86c-050104e8c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Constants\n",
    "num_samples = 2500  # Number of samples\n",
    "image_shape = (32, 32, 3)  # Shape of each image\n",
    "num_classes = 10  # Example number of classes (you can adjust as needed)\n",
    "epochs = 10000  # Number of epochs\n",
    "\n",
    "# Simulate image data (random RGB images for demonstration purposes)\n",
    "images = data['data']\n",
    "# Simulate target labels as integers (e.g., class indices)\n",
    "targets = data['targets']\n",
    "# Convert targets to one-hot encoding\n",
    "one_hot_labels = tf.keras.utils.to_categorical(targets, num_classes=num_classes)\n",
    "\n",
    "# Resize images to the required size for ResNet50V2 (224, 224, 3)\n",
    "resized_images = tf.image.resize(images, (224, 224))\n",
    "\n",
    "# Preprocess images for ResNet50V2\n",
    "processed_images = preprocess_input(resized_images)\n",
    "\n",
    "# Load ResNet50V2 model with pre-trained weights from ImageNet\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model to prevent its weights from being updated during training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers for finetuning\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)  # Pool the feature maps to 1D feature vector\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Define the final model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks for training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train the model for 10,000 epochs\n",
    "print(\"\\nTraining the Model:\")\n",
    "model.fit(\n",
    "    processed_images,\n",
    "    one_hot_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create a feature extractor using the trained base model\n",
    "print(\"\\nExtracting Features:\")\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Extract features for the input images\n",
    "features = feature_extractor.predict(processed_images, batch_size=32)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(f\"Extracted features shape: {features.shape}\")  # Example: (2500, 7, 7, 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091d580-da1a-44c2-bc7e-4bb24bc98d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define constants\n",
    "num_samples = 2500  # Number of images\n",
    "image_shape = (32, 32, 3)  # Original image shape\n",
    "num_classes = 10  # Number of classes\n",
    "epochs = 100000  # Number of epochs\n",
    "\n",
    "# Generate synthetic image data for demonstration (random RGB images)\n",
    "images = data['data']\n",
    "\n",
    "# Generate synthetic target labels (random integers in range of num_classes)\n",
    "targets = data['targets']\n",
    "# Convert integer labels to one-hot encoded vectors\n",
    "one_hot_labels = tf.keras.utils.to_categorical(targets, num_classes=num_classes)\n",
    "\n",
    "# Resize images to the required input size for ResNet50V2 (224, 224, 3)\n",
    "resized_images = tf.image.resize(images, (224, 224))\n",
    "\n",
    "# Preprocess images using ResNet50V2 preprocessing\n",
    "processed_images = preprocess_input(resized_images)\n",
    "\n",
    "# Load ResNet50V2 as the base model with pre-trained ImageNet weights\n",
    "base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model to use it as a feature extractor\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)  # Pass input through the base model\n",
    "x = GlobalAveragePooling2D()(x)  # Pool the output feature maps into a single feature vector\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)  # Output layer for classification\n",
    "\n",
    "# Define the complete model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Define callbacks to manage training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"loss\", factor=0.1, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train the model for feature extraction\n",
    "print(\"\\nTraining the model:\")\n",
    "model.fit(\n",
    "    processed_images,\n",
    "    one_hot_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create a feature extractor from the trained ResNet50V2 base model\n",
    "print(\"\\nExtracting features using the base model:\")\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Use the feature extractor to extract features from the images\n",
    "features = feature_extractor.predict(processed_images, batch_size=32)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(f\"Extracted features shape: {features.shape}\")  # Example: (2500, 7, 7, 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a4d92-2928-4e68-ac47-c70f4d78781b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
