{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64185b7-5459-4d32-8af0-4114e7643a61",
   "metadata": {},
   "source": [
    "## 1 st approach \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d76ea3f-20f2-44d8-8c07-1115f550f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d811769-d448-4ad5-a8cb-9ddadbc8039f",
   "metadata": {},
   "source": [
    "# Using resnet 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7a4622-2007-4bd4-bf81-e96811c98cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model:\n",
      "Epoch 1/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2s/step - accuracy: 0.5163 - loss: 1.4279 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.8706 - loss: 0.4068 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9141 - loss: 0.2855 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9449 - loss: 0.2128 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.9584 - loss: 0.1550 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9803 - loss: 0.1331 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9865 - loss: 0.1015 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9926 - loss: 0.0872 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9965 - loss: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0574 - learning_rate: 0.0010\n",
      "\n",
      "Extracting features using the base model:\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step\n",
      "Extracted features shape: (2500, 7, 7, 2048)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define constants\n",
    "num_samples = 2500  # Number of images\n",
    "image_shape = (32, 32, 3)  # Original image shape\n",
    "num_classes = 10  # Number of classes\n",
    "epochs = 10  # Number of epochs\n",
    "data = torch.load('../dataset/dataset/part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "\n",
    "# Generate synthetic image data for demonstration (random RGB images)\n",
    "images = data['data']\n",
    "\n",
    "# Generate synthetic target labels (random integers in range of num_classes)\n",
    "targets = data['targets']\n",
    "# Convert integer labels to one-hot encoded vectors\n",
    "one_hot_labels = tf.keras.utils.to_categorical(targets, num_classes=num_classes)\n",
    "\n",
    "# Resize images to the required input size for ResNet50V2 (224, 224, 3)\n",
    "resized_images = tf.image.resize(images, (224, 224))\n",
    "\n",
    "# Preprocess images using ResNet50V2 preprocessing\n",
    "processed_images = preprocess_input(resized_images)\n",
    "\n",
    "# Load ResNet50V2 as the base model with pre-trained ImageNet weights\n",
    "base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model to use it as a feature extractor\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)  # Pass input through the base model\n",
    "x = GlobalAveragePooling2D()(x)  # Pool the output feature maps into a single feature vector\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)  # Output layer for classification\n",
    "\n",
    "# Define the complete model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Define callbacks to manage training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"loss\", factor=0.1, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train the model for feature extraction\n",
    "print(\"\\nTraining the model:\")\n",
    "model.fit(\n",
    "    processed_images,\n",
    "    one_hot_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create a feature extractor from the trained ResNet50V2 base model\n",
    "print(\"\\nExtracting features using the base model:\")\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Use the feature extractor to extract features from the images\n",
    "features = feature_extractor.predict(processed_images, batch_size=32)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(f\"Extracted features shape: {features.shape}\")  # Example: (2500, 7, 7, 2048)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff859c-7493-498d-8048-2fafc406fd71",
   "metadata": {},
   "source": [
    "## Dimensioality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106a2de-0e51-4261-bce4-9b988e5ccde3",
   "metadata": {},
   "source": [
    "### Tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5819147f-4f8d-48b3-a299-fd4ad036af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying t-SNE to reduce dimensions to 20:\n",
      "t-SNE reduced features shape (20D): (2500, 20)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the extracted features to (num_samples, -1) for t-SNE\n",
    "# Example shape transformation: (2500, 7, 7, 2048) -> (2500, 7*7*2048)\n",
    "num_samples, height, width, channels = features.shape\n",
    "flattened_features = features.reshape(num_samples, height * width * channels)\n",
    "\n",
    "# Apply t-SNE to reduce dimensions to 20\n",
    "print(\"\\nApplying t-SNE to reduce dimensions to 20:\")\n",
    "tsne_20 = TSNE(n_components=20, random_state=42, perplexity=30, n_iter=1000, method=\"exact\")\n",
    "reduced_features_tsne = tsne_20.fit_transform(flattened_features)\n",
    "print(f\"t-SNE reduced features shape (20D): {reduced_features_tsne.shape}\")\n",
    "\n",
    "# Optionally save reduced features to a file for further use\n",
    "np.savetxt(\"20D_tsne.csv\", reduced_features_tsne, delimiter=\",\", fmt=\"%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b79652-2dd8-426f-9d24-1cfb12c71ee4",
   "metadata": {},
   "source": [
    "### Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a73e0f-1e5a-4c20-add4-b7cb92bb1b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Flatten the features\n",
    "num_samples, height, width, channels = features.shape\n",
    "flattened_features = features.reshape(num_samples, height * width * channels)\n",
    "\n",
    "input_dim = flattened_features.shape[1]\n",
    "encoding_dim = 2000  # Target reduced dimensionality\n",
    "\n",
    "# Define autoencoder for flat input\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "\n",
    "# Compile and train\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(flattened_features, flattened_features, epochs=5, batch_size=32, shuffle=True)\n",
    "\n",
    "# Use the encoder to reduce dimensions\n",
    "reduced_features_autoencoders = encoder.predict(flattened_features)\n",
    "print(\"Reduced features shape:\", reduced_features_autoencoders.shape)\n",
    "\n",
    "np.savetxt(\"2000D_autoencoders.csv\", reduced_features_autoencoders, delimiter=\",\", fmt=\"%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b0738-6876-40d4-a3fe-c9ccb067f101",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19edca6-168e-4c7a-8c7e-807b084c4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "num_samples, height, width, channels = features.shape\n",
    "flattened_features = features.reshape(num_samples, height * width * channels)\n",
    "labels = data['targets']\n",
    "lda = LDA(n_components=min(10 - 1, 200))\n",
    "reduced_features_lda = lda.fit_transform(flattened_features, labels)\n",
    "np.savetxt(\"9D_lda.csv\", reduced_features_lda, delimiter=\",\", fmt=\"%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16dce39-a1a3-4db8-b91b-26e742a097ba",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c77627-c939-48b4-ae67-2f7f1f30ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Loss: 1.5021636486053467\n",
      "Average Validation Accuracy: 0.5924000144004822\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Assuming `features` and `labels` are your LDA-transformed features and labels\n",
    "\n",
    "# Convert labels to one-hot encoding for multiclass classification\n",
    "num_classes = 10\n",
    "y_one_hot = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Apply LDA for dimensionality reduction (if not already done)\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)  # Using 5-fold cross-validation\n",
    "\n",
    "# Store performance metrics\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, val_index in kf.split(reduced_features_tsne, labels):\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = reduced_features_tsne[train_index], reduced_features_tsne[val_index]\n",
    "    y_train, y_val = y_one_hot[train_index], y_one_hot[val_index]\n",
    "    \n",
    "    # Define the functional model\n",
    "    input_layer = Input(shape=(X_train.shape[1],))  # Input shape based on reduced LDA features\n",
    "\n",
    "    # Define hidden layers\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Output layer for multiclass classification\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Build the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100, batch_size=32, shuffle=True, verbose=0  # Set verbose=0 for less output\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on validation data for this fold\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    # Append results\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average performance across all folds\n",
    "avg_val_loss = np.mean(val_losses)\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "\n",
    "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9afa23-10d5-4f00-a1d6-d70e7b978919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.8295999765396118\n",
      "Val Accuracy : 0.8511999845504761\n",
      "Average Validation Loss: 0.6281145215034485\n",
      "Average Validation Accuracy: 0.840399980545044\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Assuming `features` and `labels` are your LDA-transformed features and labels\n",
    "scaler = StandardScaler()\n",
    "reduced_features_lda = scaler.fit_transform(reduced_features_lda)\n",
    "\n",
    "# Convert labels to one-hot encoding for multiclass classification\n",
    "num_classes = 10\n",
    "y_one_hot = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Apply LDA for dimensionality reduction (if not already done)\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)  # Using 5-fold cross-validation\n",
    "\n",
    "# Store performance metrics\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, val_index in kf.split(reduced_features_lda, labels):\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = reduced_features_lda[train_index], reduced_features_lda[val_index]\n",
    "    y_train, y_val = y_one_hot[train_index], y_one_hot[val_index]\n",
    "    \n",
    "    # Define the functional model\n",
    "    input_layer = Input(shape=(X_train.shape[1],))  # Input shape based on reduced LDA features\n",
    "\n",
    "    # Define hidden layers\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    x = Dropout(0.1)(x)  # Dropout for regularization\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "\n",
    "    # Output layer for multiclass classification\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Build the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100, batch_size=32, shuffle=True, verbose=0  # Set verbose=0 for less output\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on validation data for this fold\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    # Append results\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Val Accuracy : {val_accuracy}\")\n",
    "\n",
    "# Calculate the average performance across all folds\n",
    "avg_val_loss = np.mean(val_losses)\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "\n",
    "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440d3f05-250f-4ec5-9c8a-fe5b4c0b6f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.8223999738693237\n",
      "Val Accuracy : 0.8375999927520752\n",
      "Average Validation Loss: 2.079393148422241\n",
      "Average Validation Accuracy: 0.8299999833106995\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Assuming features and labels are your LDA-transformed features and labels\n",
    "\n",
    "# Convert labels to one-hot encoding for multiclass classification\n",
    "num_classes = 10\n",
    "y_one_hot = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Apply LDA for dimensionality reduction (if not already done)\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)  # Using 5-fold cross-validation\n",
    "\n",
    "# Store performance metrics\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, val_index in kf.split(reduced_features_lda, labels):\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = reduced_features_lda[train_index], reduced_features_lda[val_index]\n",
    "    y_train, y_val = y_one_hot[train_index], y_one_hot[val_index]\n",
    "    \n",
    "    # Define the functional model\n",
    "    input_layer = Input(shape=(X_train.shape[1],))  # Input shape based on reduced LDA features\n",
    "\n",
    "    # Define hidden layers\n",
    "    x = Dense(512, activation='relu')(input_layer)\n",
    "    x = Dropout(0.2)(x)  # Dropout for regularization\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "\n",
    "    # Output layer for multiclass classification\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Build the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=500, batch_size=32, shuffle=True, verbose=0  # Set verbose=0 for less output\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on validation data for this fold\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    # Append results\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Val Accuracy : {val_accuracy}\")\n",
    "\n",
    "# Calculate the average performance across all folds\n",
    "avg_val_loss = np.mean(val_losses)\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "\n",
    "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
